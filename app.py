#!/usr/bin/env python3
"""
mlweb - Streamlitæœºå™¨å­¦ä¹ å¹³å°ä¸»åº”ç”¨
é›†æˆR Plumber APIï¼Œæä¾›å®Œæ•´çš„æœºå™¨å­¦ä¹ å·¥ä½œæµ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objs as go
from plotly.subplots import make_subplots
import plotly.express as px
import requests
import json
import time
import os
import sys
import subprocess
import tempfile
import base64
import io
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import asyncio
import aiohttp
from pathlib import Path
import logging
from logging.handlers import RotatingFileHandler
from dataclasses import dataclass
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
def setup_logging():
    """é…ç½®åº”ç”¨æ—¥å¿—"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / "app.log"
    
    # é…ç½®æ ¹æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)

logger = setup_logging()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="mlweb - æœºå™¨å­¦ä¹ å¹³å°",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/yourusername/mlweb',
        'Report a bug': 'https://github.com/yourusername/mlweb/issues',
        'About': """
        # mlwebæœºå™¨å­¦ä¹ å¹³å°
        
        ä¸€ä¸ªé›†æˆStreamlitå’ŒR Plumber APIçš„ç«¯åˆ°ç«¯æœºå™¨å­¦ä¹ å¹³å°ã€‚
        
        **ç‰ˆæœ¬**: 1.0.0
        **è®¸å¯è¯**: MIT
        """
    }
)

# è‡ªå®šä¹‰CSS
def load_css():
    """åŠ è½½è‡ªå®šä¹‰CSSæ ·å¼"""
    css_file = Path("static/css/style.css")
    
    if css_file.exists():
        try:
            with open(css_file, 'r', encoding='utf-8') as f:
                css_content = f.read()
            st.markdown(f'<style>{css_content}</style>', unsafe_allow_html=True)
            logger.info("CSSæ–‡ä»¶åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"åŠ è½½CSSæ–‡ä»¶å¤±è´¥: {e}")
            # å¦‚æœæ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ·å¼
            load_default_css()
    else:
        logger.warning(f"CSSæ–‡ä»¶ä¸å­˜åœ¨: {css_file}")
        load_default_css()

def load_default_css():
    """åŠ è½½é»˜è®¤CSSæ ·å¼ï¼ˆå¤‡ç”¨ï¼‰"""
    default_css = """
    /* åŸºç¡€æ ·å¼ç¡®ä¿åº”ç”¨å¯è¿è¡Œ */
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .section-title {
        font-size: 1.8rem;
        font-weight: bold;
        color: #3949AB;
        margin-top: 2rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #E3F2FD;
    }
    """
    st.markdown(f'<style>{default_css}</style>', unsafe_allow_html=True)

# åº”ç”¨é…ç½®ç±»
@dataclass
class AppConfig:
    """åº”ç”¨é…ç½®"""
    API_BASE_URL: str = "http://localhost:8000"
    API_TIMEOUT: int = 60
    MAX_FILE_SIZE: int = 100 * 1024 * 1024  # 100MB
    SUPPORTED_FILE_TYPES: List[str] = None
    CACHE_DIR: str = ".cache"
    
    def __post_init__(self):
        if self.SUPPORTED_FILE_TYPES is None:
            self.SUPPORTED_FILE_TYPES = [
                "csv", "xlsx", "xls", "json", "parquet", 
                "feather", "pickle", "pkl", "txt"
            ]

# ä¼šè¯çŠ¶æ€ç®¡ç†
class SessionState:
    """ç®¡ç†Streamlitä¼šè¯çŠ¶æ€"""
    def __init__(self):
        # åº”ç”¨çŠ¶æ€
        self.current_step = 1
        self.steps = {
            1: "ğŸ“Š æ•°æ®åŠ è½½",
            2: "ğŸ” æ•°æ®æ¢ç´¢",
            3: "ğŸ§¹ æ•°æ®é¢„å¤„ç†",
            4: "ğŸ¤– æ¨¡å‹è®­ç»ƒ",
            5: "ğŸ“ˆ æ¨¡å‹è¯„ä¼°",
            6: "ğŸš€ æ¨¡å‹éƒ¨ç½²",
            7: "âš¡ å®æ—¶é¢„æµ‹"
        }
        
        # æ•°æ®çŠ¶æ€
        self.data_loaded = False
        self.raw_data = None
        self.processed_data = None
        self.train_data = None
        self.test_data = None
        self.target_column = None
        self.problem_type = "classification"  # "classification" æˆ– "regression"
        
        # æ¨¡å‹çŠ¶æ€
        self.models_trained = False
        self.training_result = None
        self.selected_model = None
        self.evaluation_result = None
        
        # APIçŠ¶æ€
        self.api_available = False
        self.api_status = {}
        self.last_api_check = None
        
        # ç¼“å­˜
        self.cache = {}
        
        # æ—¥å¿—
        self.logs = []
        
    def reset(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€"""
        self.__init__()
        
    def log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.logs.append({
            "timestamp": timestamp,
            "level": level,
            "message": message
        })
        logger.log(getattr(logging, level), message)
        
    def get_logs(self, level: str = None):
        """è·å–æ—¥å¿—"""
        if level:
            return [log for log in self.logs if log["level"] == level]
        return self.logs

# åˆå§‹åŒ–
load_css()
config = AppConfig()
state = SessionState()

# APIå®¢æˆ·ç«¯
class APIClient:
    """R Plumber APIå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = None, timeout: int = 60):
        self.base_url = base_url or config.API_BASE_URL
        self.timeout = timeout
        self.session = None
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_time": 0
        }
        
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
            
    def _make_url(self, endpoint: str) -> str:
        """æ„å»ºå®Œæ•´URL"""
        return f"{self.base_url}/{endpoint.lstrip('/')}"
    
    def check_health(self) -> Dict:
        """æ£€æŸ¥APIå¥åº·çŠ¶æ€"""
        try:
            start_time = time.time()
            response = requests.get(
                self._make_url("health"),
                timeout=5
            )
            elapsed = time.time() - start_time
            
            self.stats["total_requests"] += 1
            if response.status_code == 200:
                self.stats["successful_requests"] += 1
                status = response.json()
                status["response_time"] = elapsed
                return status
            else:
                self.stats["failed_requests"] += 1
                return {
                    "status": "unhealthy",
                    "error": f"HTTP {response.status_code}",
                    "response_time": elapsed
                }
        except Exception as e:
            self.stats["failed_requests"] += 1
            return {
                "status": "unreachable",
                "error": str(e),
                "response_time": 0
            }
    
    async def async_request(self, method: str, endpoint: str, **kwargs) -> Dict:
        """å¼‚æ­¥HTTPè¯·æ±‚"""
        if not self.session:
            self.session = aiohttp.ClientSession()
            
        url = self._make_url(endpoint)
        start_time = time.time()
        
        try:
            async with self.session.request(method, url, **kwargs) as response:
                elapsed = time.time() - start_time
                self.stats["total_requests"] += 1
                
                if response.status == 200:
                    self.stats["successful_requests"] += 1
                    data = await response.json()
                    data["response_time"] = elapsed
                    return data
                else:
                    self.stats["failed_requests"] += 1
                    error_text = await response.text()
                    return {
                        "success": False,
                        "error": f"HTTP {response.status}: {error_text}",
                        "response_time": elapsed
                    }
        except Exception as e:
            self.stats["failed_requests"] += 1
            return {
                "success": False,
                "error": str(e),
                "response_time": time.time() - start_time
            }
    
    def sync_request(self, method: str, endpoint: str, **kwargs) -> Dict:
        """åŒæ­¥HTTPè¯·æ±‚"""
        url = self._make_url(endpoint)
        start_time = time.time()
        
        try:
            response = requests.request(
                method, url,
                timeout=self.timeout,
                **kwargs
            )
            elapsed = time.time() - start_time
            self.stats["total_requests"] += 1
            
            if response.status_code == 200:
                self.stats["successful_requests"] += 1
                data = response.json()
                data["response_time"] = elapsed
                return data
            else:
                self.stats["failed_requests"] += 1
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "response_time": elapsed
                }
        except Exception as e:
            self.stats["failed_requests"] += 1
            return {
                "success": False,
                "error": str(e),
                "response_time": time.time() - start_time
            }
    
    def get_stats(self) -> Dict:
        """è·å–APIç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "success_rate": (
                self.stats["successful_requests"] / self.stats["total_requests"] 
                if self.stats["total_requests"] > 0 else 0
            )
        }

# æ•°æ®å¤„ç†å™¨
class DataProcessor:
    """æ•°æ®å¤„ç†å·¥å…·ç±»"""
    
    @staticmethod
    def detect_file_type(file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç±»å‹"""
        ext = Path(file_path).suffix.lower().lstrip('.')
        return ext
    
    @staticmethod
    def load_file(file_path: str, file_type: str = None) -> pd.DataFrame:
        """åŠ è½½æ–‡ä»¶ä¸ºDataFrame"""
        if file_type is None:
            file_type = DataProcessor.detect_file_type(file_path)
            
        try:
            if file_type == 'csv':
                return pd.read_csv(file_path)
            elif file_type in ['xlsx', 'xls']:
                return pd.read_excel(file_path)
            elif file_type == 'json':
                return pd.read_json(file_path)
            elif file_type == 'parquet':
                return pd.read_parquet(file_path)
            elif file_type == 'feather':
                return pd.read_feather(file_path)
            elif file_type in ['pickle', 'pkl']:
                return pd.read_pickle(file_path)
            elif file_type == 'txt':
                return pd.read_csv(file_path, sep='\t')
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
        except Exception as e:
            logger.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    @staticmethod
    def analyze_data(df: pd.DataFrame) -> Dict:
        """åˆ†ææ•°æ®ç‰¹å¾"""
        analysis = {
            "shape": df.shape,
            "dtypes": df.dtypes.astype(str).to_dict(),
            "missing_values": df.isnull().sum().to_dict(),
            "missing_percentage": (df.isnull().sum() / len(df) * 100).to_dict(),
            "numeric_stats": {},
            "categorical_stats": {},
            "correlations": {}
        }
        
        # æ•°å€¼åˆ—ç»Ÿè®¡
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            analysis["numeric_stats"] = df[numeric_cols].describe().to_dict()
            
            # ç›¸å…³æ€§çŸ©é˜µ
            if len(numeric_cols) > 1:
                analysis["correlations"] = df[numeric_cols].corr().to_dict()
        
        # åˆ†ç±»åˆ—ç»Ÿè®¡
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        for col in categorical_cols:
            analysis["categorical_stats"][col] = {
                "unique_values": df[col].nunique(),
                "value_counts": df[col].value_counts().head(10).to_dict()
            }
        
        return analysis
    
    @staticmethod
    def create_data_visualizations(df: pd.DataFrame) -> Dict:
        """åˆ›å»ºæ•°æ®å¯è§†åŒ–"""
        viz = {}
        
        # æ•°å€¼åˆ—åˆ†å¸ƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            for col in numeric_cols[:5]:  # é™åˆ¶å‰5ä¸ªæ•°å€¼åˆ—
                fig = px.histogram(df, x=col, nbins=50, title=f"{col}åˆ†å¸ƒ")
                viz[f"hist_{col}"] = fig
        
        # ç›¸å…³æ€§çƒ­å›¾
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr()
            fig = px.imshow(
                corr_matrix,
                title="ç‰¹å¾ç›¸å…³æ€§çƒ­å›¾",
                color_continuous_scale="RdBu"
            )
            viz["correlation_heatmap"] = fig
        
        # æ•£ç‚¹å›¾çŸ©é˜µ
        if len(numeric_cols) >= 2:
            fig = px.scatter_matrix(
                df[numeric_cols[:4]],  # é™åˆ¶å‰4ä¸ªç‰¹å¾
                title="æ•£ç‚¹å›¾çŸ©é˜µ"
            )
            viz["scatter_matrix"] = fig
        
        return viz

# æ¨¡å‹ç®¡ç†å™¨
class ModelManager:
    """æ¨¡å‹ç®¡ç†å·¥å…·ç±»"""
    
    @staticmethod
    def get_model_info(model_result: Dict) -> Dict:
        """æå–æ¨¡å‹ä¿¡æ¯"""
        info = {
            "name": model_result.get("name", "æœªçŸ¥æ¨¡å‹"),
            "type": model_result.get("type", "æœªçŸ¥ç±»å‹"),
            "performance": {},
            "parameters": {},
            "training_info": {}
        }
        
        # æå–æ€§èƒ½æŒ‡æ ‡
        if "performance" in model_result:
            perf = model_result["performance"]
            info["performance"] = {
                "accuracy": perf.get("accuracy"),
                "precision": perf.get("precision"),
                "recall": perf.get("recall"),
                "f1": perf.get("f1"),
                "auc": perf.get("auc"),
                "rmse": perf.get("rmse"),
                "mae": perf.get("mae"),
                "r2": perf.get("r2")
            }
        
        # æå–å‚æ•°
        if "parameters" in model_result:
            info["parameters"] = model_result["parameters"]
            
        # æå–è®­ç»ƒä¿¡æ¯
        if "training_info" in model_result:
            info["training_info"] = model_result["training_info"]
            
        return info

# é¡µé¢ç»„ä»¶
class PageComponents:
    """é¡µé¢ç»„ä»¶å·¥å‚"""
    
    @staticmethod
    def create_header():
        """åˆ›å»ºé¡µé¢å¤´éƒ¨"""
        st.markdown('<h1 class="main-title fade-in">ğŸ¤– mlwebæœºå™¨å­¦ä¹ å¹³å°</h1>', 
                   unsafe_allow_html=True)
        st.markdown("""
        <div class="alert alert-info">
        <strong>ğŸš€ ç«¯åˆ°ç«¯æœºå™¨å­¦ä¹ å¹³å°</strong> - é›†æˆæ•°æ®æ¢ç´¢ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²çš„å…¨æµç¨‹å·¥å…·
        </div>
        """, unsafe_allow_html=True)
    
    @staticmethod
    def create_sidebar():
        """åˆ›å»ºä¾§è¾¹æ """
        with st.sidebar:
            st.image("static/images/logo.png", width=200)
            
            st.markdown("## ğŸ§­ å¯¼èˆª")
            for step_num, step_name in state.steps.items():
                col1, col2 = st.columns([1, 4])
                with col1:
                    st.markdown(f"**{step_num}**")
                with col2:
                    if st.button(
                        step_name,
                        key=f"nav_{step_num}",
                        use_container_width=True,
                        disabled=(step_num > state.current_step)
                    ):
                        state.current_step = step_num
                        st.rerun()
            
            st.divider()
            
            # ç³»ç»ŸçŠ¶æ€
            st.markdown("## ğŸ“Š ç³»ç»ŸçŠ¶æ€")
            
            # APIçŠ¶æ€
            api_status_color = {
                "healthy": "ğŸŸ¢",
                "unhealthy": "ğŸŸ¡",
                "unreachable": "ğŸ”´"
            }
            api_status = state.api_status.get("status", "unknown")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("APIçŠ¶æ€", api_status_color.get(api_status, "âšª"))
            with col2:
                st.metric("å½“å‰æ­¥éª¤", f"{state.current_step}/7")
            
            if state.api_available:
                response_time = state.api_status.get("response_time", 0)
                st.caption(f"APIå“åº”æ—¶é—´: {response_time:.3f}ç§’")
            
            st.divider()
            
            # å·¥å…·
            st.markdown("## ğŸ› ï¸ å·¥å…·")
            
            if st.button("ğŸ”„ é‡ç½®ä¼šè¯", use_container_width=True):
                state.reset()
                st.rerun()
                
            if st.button("ğŸ“Š æŸ¥çœ‹æ—¥å¿—", use_container_width=True):
                PageComponents.show_logs()
                
            if st.button("âš™ï¸ ç³»ç»Ÿè®¾ç½®", use_container_width=True):
                PageComponents.show_settings()
    
    @staticmethod
    def show_logs():
        """æ˜¾ç¤ºæ—¥å¿—çª—å£"""
        with st.expander("ğŸ“‹ ç³»ç»Ÿæ—¥å¿—", expanded=True):
            logs = state.get_logs()
            if logs:
                for log in reversed(logs[-10:]):  # æ˜¾ç¤ºæœ€è¿‘10æ¡æ—¥å¿—
                    level_color = {
                        "INFO": "blue",
                        "WARNING": "orange",
                        "ERROR": "red",
                        "DEBUG": "gray"
                    }
                    st.markdown(
                        f'<span style="color: {level_color.get(log["level"], "black")}">'
                        f'[{log["timestamp"]}] {log["level"]}: {log["message"]}'
                        f'</span>',
                        unsafe_allow_html=True
                    )
            else:
                st.info("æš‚æ— æ—¥å¿—")
    
    @staticmethod
    def show_settings():
        """æ˜¾ç¤ºç³»ç»Ÿè®¾ç½®"""
        with st.expander("âš™ï¸ ç³»ç»Ÿè®¾ç½®", expanded=True):
            st.subheader("APIè®¾ç½®")
            
            api_url = st.text_input("APIåœ°å€", value=config.API_BASE_URL)
            timeout = st.number_input("è¶…æ—¶æ—¶é—´(ç§’)", min_value=1, max_value=300, value=config.API_TIMEOUT)
            
            if st.button("ä¿å­˜è®¾ç½®"):
                config.API_BASE_URL = api_url
                config.API_TIMEOUT = timeout
                st.success("è®¾ç½®å·²ä¿å­˜")
            
            st.divider()
            
            st.subheader("æ•°æ®è®¾ç½®")
            max_file_size = st.number_input("æœ€å¤§æ–‡ä»¶å¤§å°(MB)", min_value=1, max_value=1000, 
                                           value=config.MAX_FILE_SIZE // (1024*1024))
            
            if st.button("æµ‹è¯•APIè¿æ¥"):
                client = APIClient()
                status = client.check_health()
                state.api_status = status
                state.api_available = (status.get("status") == "healthy")
                
                if state.api_available:
                    st.success("âœ… APIè¿æ¥æ­£å¸¸")
                else:
                    st.error(f"âŒ APIè¿æ¥å¤±è´¥: {status.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    @staticmethod
    def create_progress_bar():
        """åˆ›å»ºè¿›åº¦æ¡"""
        progress = state.current_step / len(state.steps)
        
        st.markdown("""
        <div class="progress-container">
            <div class="progress-bar" style="width: {:.1%}"></div>
        </div>
        """.format(progress), unsafe_allow_html=True)
        
        col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
        steps_list = list(state.steps.values())
        for i, (col, step_name) in enumerate(zip([col1, col2, col3, col4, col5, col6, col7], steps_list), 1):
            with col:
                if i < state.current_step:
                    st.markdown(f"âœ… {step_name.split(' ')[1]}")
                elif i == state.current_step:
                    st.markdown(f"ğŸ“ **{step_name.split(' ')[1]}**")
                else:
                    st.markdown(f"âšª {step_name.split(' ')[1]}")
    
    @staticmethod
    def create_footer():
        """åˆ›å»ºé¡µè„š"""
        st.divider()
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**ç‰ˆæœ¬**: 1.0.0")
        with col2:
            st.markdown("**æœ€åæ›´æ–°**: 2024-01-01")
        with col3:
            st.markdown("**çŠ¶æ€**: ğŸŸ¢ åœ¨çº¿")

# é¡µé¢æ§åˆ¶å™¨
class PageController:
    """é¡µé¢æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.pages = {
            1: self.page_data_loading,
            2: self.page_data_exploration,
            3: self.page_data_preprocessing,
            4: self.page_model_training,
            5: self.page_model_evaluation,
            6: self.page_model_deployment,
            7: self.page_realtime_prediction
        }
    
    def render(self):
        """æ¸²æŸ“å½“å‰é¡µé¢"""
        PageComponents.create_header()
        PageComponents.create_sidebar()
        PageComponents.create_progress_bar()
        
        # æ˜¾ç¤ºå½“å‰é¡µé¢
        page_func = self.pages.get(state.current_step)
        if page_func:
            page_func()
        else:
            st.error("é¡µé¢ä¸å­˜åœ¨")
            
        PageComponents.create_footer()
    
    def page_data_loading(self):
        """æ•°æ®åŠ è½½é¡µé¢"""
        st.markdown('<h2 class="section-title">ğŸ“Š æ•°æ®åŠ è½½</h2>', 
                   unsafe_allow_html=True)
        
        # æ•°æ®æºé€‰æ‹©
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æº",
            ["ä¸Šä¼ æ–‡ä»¶", "ç¤ºä¾‹æ•°æ®", "æ•°æ®åº“è¿æ¥", "APIæ¥å£"],
            horizontal=True
        )
        
        if data_source == "ä¸Šä¼ æ–‡ä»¶":
            self._handle_file_upload()
        elif data_source == "ç¤ºä¾‹æ•°æ®":
            self._handle_example_data()
        elif data_source == "æ•°æ®åº“è¿æ¥":
            self._handle_database_connection()
        else:
            self._handle_api_source()
    
    def _handle_file_upload(self):
        """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ•°æ®æ–‡ä»¶",
            type=config.SUPPORTED_FILE_TYPES,
            help=f"æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {', '.join(config.SUPPORTED_FILE_TYPES)}"
        )
        
        if uploaded_file is not None:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = len(uploaded_file.getvalue())
            if file_size > config.MAX_FILE_SIZE:
                st.error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({file_size/(1024*1024):.1f}MB > "
                        f"{config.MAX_FILE_SIZE/(1024*1024):.1f}MB)")
                return
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            try:
                # åŠ è½½æ•°æ®
                with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                    df = DataProcessor.load_file(tmp_path)
                    state.raw_data = df
                    state.data_loaded = True
                    
                    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
                    
                    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                    with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ", expanded=True):
                        tab1, tab2, tab3 = st.tabs(["æ•°æ®å¤´", "æ•°æ®å°¾", "éšæœºæ ·æœ¬"])
                        with tab1:
                            st.dataframe(df.head(10), use_container_width=True)
                        with tab2:
                            st.dataframe(df.tail(10), use_container_width=True)
                        with tab3:
                            st.dataframe(df.sample(10), use_container_width=True)
                    
                    # æ•°æ®ä¿¡æ¯
                    with st.expander("ğŸ“Š æ•°æ®ä¿¡æ¯", expanded=False):
                        st.write(f"**æ•°æ®ç±»å‹**:")
                        for col, dtype in df.dtypes.items():
                            st.write(f"- {col}: {dtype}")
                    
                    # ä¸‹ä¸€æ­¥æŒ‰é’®
                    if st.button("ä¸‹ä¸€æ­¥: æ•°æ®æ¢ç´¢", type="primary", use_container_width=True):
                        state.current_step = 2
                        st.rerun()
                        
            except Exception as e:
                st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
                logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
    
    def _handle_example_data(self):
        """å¤„ç†ç¤ºä¾‹æ•°æ®"""
        example_options = {
            "é¸¢å°¾èŠ±æ•°æ®é›†": "iris",
            "æ³°å¦å°¼å…‹å·æ•°æ®é›†": "titanic",
            "æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†": "boston",
            "ç³–å°¿ç—…æ•°æ®é›†": "diabetes",
            "è‘¡è„é…’æ•°æ®é›†": "wine",
            "ä¹³è…ºç™Œæ•°æ®é›†": "breast_cancer"
        }
        
        selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹æ•°æ®é›†", list(example_options.keys()))
        
        if st.button("åŠ è½½ç¤ºä¾‹æ•°æ®", type="primary"):
            with st.spinner("æ­£åœ¨åŠ è½½ç¤ºä¾‹æ•°æ®..."):
                try:
                    # è¿™é‡Œå¯ä»¥è°ƒç”¨R APIæˆ–ä½¿ç”¨æœ¬åœ°æ•°æ®
                    if example_options[selected_example] == "iris":
                        from sklearn.datasets import load_iris
                        data = load_iris()
                        df = pd.DataFrame(data.data, columns=data.feature_names)
                        df['target'] = data.target
                        
                    elif example_options[selected_example] == "titanic":
                        df = pd.read_csv("https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv")
                        
                    elif example_options[selected_example] == "boston":
                        from sklearn.datasets import fetch_openml
                        boston = fetch_openml(name='boston', version=1)
                        df = pd.DataFrame(boston.data, columns=boston.feature_names)
                        df['target'] = boston.target
                        
                    elif example_options[selected_example] == "diabetes":
                        from sklearn.datasets import load_diabetes
                        diabetes = load_diabetes()
                        df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
                        df['target'] = diabetes.target
                        
                    state.raw_data = df
                    state.data_loaded = True
                    
                    st.success(f"âœ… ç¤ºä¾‹æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
                    
                    with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ", expanded=True):
                        st.dataframe(df.head(), use_container_width=True)
                    
                    if st.button("ä¸‹ä¸€æ­¥: æ•°æ®æ¢ç´¢", type="primary", use_container_width=True):
                        state.current_step = 2
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"åŠ è½½ç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")
    
    def _handle_database_connection(self):
        """å¤„ç†æ•°æ®åº“è¿æ¥"""
        st.info("æ•°æ®åº“è¿æ¥åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
        
        # æ•°æ®åº“é…ç½®
        db_type = st.selectbox("æ•°æ®åº“ç±»å‹", ["PostgreSQL", "MySQL"])
        
        col1, col2 = st.columns(2)
        with col1:
            host = st.text_input("ä¸»æœº", "localhost")
            port = st.number_input("ç«¯å£", value=5432 if db_type == "PostgreSQL" else 3306)
        with col2:
            database = st.text_input("æ•°æ®åº“å", "st_db")
            username = st.text_input("ç”¨æˆ·å", "aikemi001")
            password = st.text_input("å¯†ç ", type="snut3426")
        
        query = st.text_area("SQLæŸ¥è¯¢", "SELECT * FROM table_name LIMIT 1000")
        
        if st.button("è¿æ¥æ•°æ®åº“", type="primary"):
            st.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
    
    def _handle_api_source(self):
        """å¤„ç†APIæ•°æ®æº"""
        st.info("APIæ•°æ®æºåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
        
        api_url = st.text_input("APIåœ°å€", "https://api.example.com/data")
        api_key = st.text_input("APIå¯†é’¥", type="password")
        
        if st.button("ä»APIåŠ è½½æ•°æ®", type="primary"):
            st.info("APIæ•°æ®æºåŠŸèƒ½å°†åœ¨åç»­ç‰ˆæœ¬ä¸­å®ç°")
    
    def page_data_exploration(self):
        """æ•°æ®æ¢ç´¢é¡µé¢"""
        st.markdown('<h2 class="section-title">ğŸ” æ•°æ®æ¢ç´¢</h2>', 
                   unsafe_allow_html=True)
        
        if not state.data_loaded:
            st.warning("è¯·å…ˆåŠ è½½æ•°æ®")
            st.stop()
        
        df = state.raw_data
        
        # æ¢ç´¢é€‰é¡¹å¡
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ğŸ“Š æ•°æ®æ¦‚è§ˆ", 
            "ğŸ“ˆ æ•°æ®å¯è§†åŒ–", 
            "ğŸ”¢ ç»Ÿè®¡åˆ†æ", 
            "ğŸ” æ•°æ®è´¨é‡", 
            "ğŸ¯ ç›®æ ‡å˜é‡"
        ])
        
        with tab1:
            self._show_data_overview(df)
        with tab2:
            self._show_data_visualization(df)
        with tab3:
            self._show_statistical_analysis(df)
        with tab4:
            self._show_data_quality(df)
        with tab5:
            self._show_target_variable_selection(df)
    
    def _show_data_overview(self, df):
        """æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ"""
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»è¡Œæ•°", df.shape[0])
        with col2:
            st.metric("æ€»åˆ—æ•°", df.shape[1])
        with col3:
            st.metric("å†…å­˜ä½¿ç”¨", f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")
        with col4:
            missing_total = df.isnull().sum().sum()
            st.metric("ç¼ºå¤±å€¼æ€»æ•°", missing_total)
        
        # æ•°æ®ç±»å‹åˆ†å¸ƒ
        st.subheader("æ•°æ®ç±»å‹åˆ†å¸ƒ")
        dtype_counts = df.dtypes.value_counts()
        fig = px.pie(
            values=dtype_counts.values,
            names=dtype_counts.index.astype(str),
            title="æ•°æ®ç±»å‹åˆ†å¸ƒ"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # åˆ—ä¿¡æ¯è¡¨æ ¼
        st.subheader("åˆ—ä¿¡æ¯")
        col_info = pd.DataFrame({
            'åˆ—å': df.columns,
            'æ•°æ®ç±»å‹': df.dtypes.values,
            'éç©ºå€¼': df.count().values,
            'ç¼ºå¤±å€¼': df.isnull().sum().values,
            'ç¼ºå¤±ç‡%': (df.isnull().sum() / len(df) * 100).round(2).values,
            'å”¯ä¸€å€¼': df.nunique().values,
            'ç¤ºä¾‹å€¼': df.iloc[0].values
        })
        st.dataframe(col_info, use_container_width=True)
    
    def _show_data_visualization(self, df):
        """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–"""
        # é€‰æ‹©å¯è§†åŒ–ç±»å‹
        viz_type = st.selectbox(
            "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
            ["åˆ†å¸ƒå›¾", "æ•£ç‚¹å›¾", "ç®±çº¿å›¾", "å°æç´å›¾", "çƒ­åŠ›å›¾", "ç›¸å…³æ€§çŸ©é˜µ"]
        )
        
        if viz_type == "åˆ†å¸ƒå›¾":
            col = st.selectbox("é€‰æ‹©åˆ—", df.select_dtypes(include=[np.number]).columns)
            if col:
                fig = px.histogram(df, x=col, nbins=50, title=f"{col}åˆ†å¸ƒ")
                st.plotly_chart(fig, use_container_width=True)
                
        elif viz_type == "æ•£ç‚¹å›¾":
            col1 = st.selectbox("Xè½´", df.select_dtypes(include=[np.number]).columns)
            col2 = st.selectbox("Yè½´", df.select_dtypes(include=[np.number]).columns)
            color_col = st.selectbox("é¢œè‰²åˆ—(å¯é€‰)", ["æ— "] + list(df.columns))
            
            if col1 and col2:
                if color_col != "æ— ":
                    fig = px.scatter(df, x=col1, y=col2, color=color_col, 
                                    title=f"{col1} vs {col2}")
                else:
                    fig = px.scatter(df, x=col1, y=col2, title=f"{col1} vs {col2}")
                st.plotly_chart(fig, use_container_width=True)
                
        elif viz_type == "ç®±çº¿å›¾":
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            selected_cols = st.multiselect("é€‰æ‹©åˆ—", numeric_cols, default=list(numeric_cols[:3]))
            
            if selected_cols:
                fig = px.box(df[selected_cols], title="ç®±çº¿å›¾")
                st.plotly_chart(fig, use_container_width=True)
                
        elif viz_type == "çƒ­åŠ›å›¾":
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 1:
                corr_matrix = df[numeric_cols].corr()
                fig = px.imshow(corr_matrix, title="ç›¸å…³æ€§çƒ­åŠ›å›¾", 
                               color_continuous_scale="RdBu")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—æ¥ç”Ÿæˆçƒ­åŠ›å›¾")
    
    def _show_statistical_analysis(self, df):
        """æ˜¾ç¤ºç»Ÿè®¡åˆ†æ"""
        st.subheader("æè¿°æ€§ç»Ÿè®¡")
        st.dataframe(df.describe(), use_container_width=True)
        
        # ååº¦å’Œå³°åº¦
        st.subheader("åˆ†å¸ƒç‰¹æ€§")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            from scipy import stats
            
            dist_stats = []
            for col in numeric_cols:
                skewness = stats.skew(df[col].dropna())
                kurtosis = stats.kurtosis(df[col].dropna())
                dist_stats.append({
                    'åˆ—å': col,
                    'ååº¦': f"{skewness:.4f}",
                    'å³°åº¦': f"{kurtosis:.4f}",
                    'æ­£æ€æ€§(på€¼)': f"{stats.shapiro(df[col].dropna())[1]:.4f}"
                })
            
            dist_df = pd.DataFrame(dist_stats)
            st.dataframe(dist_df, use_container_width=True)
    
    def _show_data_quality(self, df):
        """æ˜¾ç¤ºæ•°æ®è´¨é‡åˆ†æ"""
        # ç¼ºå¤±å€¼åˆ†æ
        st.subheader("ç¼ºå¤±å€¼åˆ†æ")
        missing_df = pd.DataFrame({
            'åˆ—å': df.columns,
            'ç¼ºå¤±å€¼æ•°é‡': df.isnull().sum().values,
            'ç¼ºå¤±ç‡%': (df.isnull().sum() / len(df) * 100).round(2).values
        }).sort_values('ç¼ºå¤±ç‡%', ascending=False)
        
        st.dataframe(missing_df, use_container_width=True)
        
        # ç¼ºå¤±å€¼å¯è§†åŒ–
        if missing_df['ç¼ºå¤±å€¼æ•°é‡'].sum() > 0:
            fig = px.bar(missing_df, x='åˆ—å', y='ç¼ºå¤±ç‡%', title='ç¼ºå¤±å€¼åˆ†å¸ƒ')
            st.plotly_chart(fig, use_container_width=True)
        
        # é‡å¤å€¼åˆ†æ
        st.subheader("é‡å¤å€¼åˆ†æ")
        duplicate_count = df.duplicated().sum()
        st.metric("é‡å¤è¡Œæ•°", duplicate_count)
        
        if duplicate_count > 0:
            st.warning(f"å‘ç° {duplicate_count} ä¸ªé‡å¤è¡Œ")
            if st.button("æŸ¥çœ‹é‡å¤è¡Œ"):
                st.dataframe(df[df.duplicated()], use_container_width=True)
        
        # å¼‚å¸¸å€¼æ£€æµ‹
        st.subheader("å¼‚å¸¸å€¼æ£€æµ‹")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            outlier_method = st.selectbox("æ£€æµ‹æ–¹æ³•", ["IQRæ–¹æ³•", "Z-scoreæ–¹æ³•"])
            
            if st.button("æ£€æµ‹å¼‚å¸¸å€¼"):
                with st.spinner("æ­£åœ¨æ£€æµ‹å¼‚å¸¸å€¼..."):
                    outliers_summary = {}
                    
                    for col in numeric_cols:
                        data = df[col].dropna()
                        
                        if outlier_method == "IQRæ–¹æ³•":
                            Q1 = data.quantile(0.25)
                            Q3 = data.quantile(0.75)
                            IQR = Q3 - Q1
                            lower_bound = Q1 - 1.5 * IQR
                            upper_bound = Q3 + 1.5 * IQR
                            outliers = data[(data < lower_bound) | (data > upper_bound)]
                        else:  # Z-scoreæ–¹æ³•
                            from scipy import stats
                            z_scores = np.abs(stats.zscore(data))
                            outliers = data[z_scores > 3]
                        
                        outliers_summary[col] = {
                            'å¼‚å¸¸å€¼æ•°é‡': len(outliers),
                            'å¼‚å¸¸å€¼æ¯”ä¾‹%': (len(outliers) / len(data) * 100),
                            'æœ€å°å€¼': data.min(),
                            'æœ€å¤§å€¼': data.max()
                        }
                    
                    outliers_df = pd.DataFrame(outliers_summary).T
                    st.dataframe(outliers_df, use_container_width=True)
    
    def _show_target_variable_selection(self, df):
        """æ˜¾ç¤ºç›®æ ‡å˜é‡é€‰æ‹©"""
        st.subheader("ç›®æ ‡å˜é‡è®¾ç½®")
        
        # é€‰æ‹©ç›®æ ‡å˜é‡
        target_col = st.selectbox(
            "é€‰æ‹©ç›®æ ‡å˜é‡(è¦é¢„æµ‹çš„åˆ—)",
            df.columns,
            help="è¿™æ˜¯æ¨¡å‹è¦é¢„æµ‹çš„å˜é‡"
        )
        
        # æ£€æµ‹é—®é¢˜ç±»å‹
        if target_col:
            unique_values = df[target_col].nunique()
            
            if df[target_col].dtype in ['object', 'category'] or unique_values < 10:
                problem_type = "classification"
                st.info(f"æ£€æµ‹ä¸ºåˆ†ç±»é—®é¢˜ (ç›®æ ‡å˜é‡æœ‰ {unique_values} ä¸ªå”¯ä¸€å€¼)")
            else:
                problem_type = "regression"
                st.info("æ£€æµ‹ä¸ºå›å½’é—®é¢˜")
            
            # ç›®æ ‡å˜é‡åˆ†å¸ƒ
            st.subheader("ç›®æ ‡å˜é‡åˆ†å¸ƒ")
            
            if problem_type == "classification":
                value_counts = df[target_col].value_counts()
                fig = px.pie(
                    values=value_counts.values,
                    names=value_counts.index,
                    title="ç›®æ ‡å˜é‡ç±»åˆ«åˆ†å¸ƒ"
                )
            else:
                fig = px.histogram(df, x=target_col, nbins=50, 
                                 title="ç›®æ ‡å˜é‡åˆ†å¸ƒ")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ä¿å­˜é€‰æ‹©
            state.target_column = target_col
            state.problem_type = problem_type
            
            # ä¸‹ä¸€æ­¥æŒ‰é’®
            if st.button("ä¸‹ä¸€æ­¥: æ•°æ®é¢„å¤„ç†", type="primary", use_container_width=True):
                state.current_step = 3
                st.rerun()
    
    def page_data_preprocessing(self):
        """æ•°æ®é¢„å¤„ç†é¡µé¢"""
        st.markdown('<h2 class="section-title">ğŸ§¹ æ•°æ®é¢„å¤„ç†</h2>', 
                   unsafe_allow_html=True)
        
        if not state.data_loaded or state.target_column is None:
            st.warning("è¯·å…ˆåŠ è½½æ•°æ®å¹¶é€‰æ‹©ç›®æ ‡å˜é‡")
            st.stop()
        
        df = state.raw_data
        
        # é¢„å¤„ç†é…ç½®
        st.subheader("é¢„å¤„ç†é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("## ç¼ºå¤±å€¼å¤„ç†")
            missing_strategy = st.selectbox(
                "å¤„ç†ç­–ç•¥",
                ["åˆ é™¤ç¼ºå¤±è¡Œ", "å‡å€¼å¡«å……", "ä¸­ä½æ•°å¡«å……", "ä¼—æ•°å¡«å……", "æ’å€¼æ³•", "KNNå¡«å……"]
            )
            
            st.markdown("## å¼‚å¸¸å€¼å¤„ç†")
            handle_outliers = st.checkbox("å¤„ç†å¼‚å¸¸å€¼", value=True)
            if handle_outliers:
                outlier_method = st.selectbox(
                    "å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•",
                    ["IQRè¿‡æ»¤", "Z-scoreè¿‡æ»¤", "ä¿ç•™å¼‚å¸¸å€¼"]
                )
        
        with col2:
            st.markdown("## ç‰¹å¾å·¥ç¨‹")
            scale_features = st.checkbox("æ ‡å‡†åŒ–ç‰¹å¾", value=True)
            encode_categorical = st.checkbox("ç¼–ç åˆ†ç±»å˜é‡", value=True)
            
            st.markdown("## ç‰¹å¾é€‰æ‹©")
            feature_selection = st.checkbox("å¯ç”¨ç‰¹å¾é€‰æ‹©", value=False)
            if feature_selection:
                selection_method = st.selectbox(
                    "é€‰æ‹©æ–¹æ³•",
                    ["ç›¸å…³æ€§è¿‡æ»¤", "æ–¹å·®è¿‡æ»¤", "é€’å½’æ¶ˆé™¤", "åŸºäºæ¨¡å‹"]
                )
        
        # æ•°æ®åˆ†å‰²é…ç½®
        st.subheader("æ•°æ®åˆ†å‰²")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
        with col2:
            validation_size = st.slider("éªŒè¯é›†æ¯”ä¾‹", 0.0, 0.3, 0.1, 0.05)
        with col3:
            random_seed = st.number_input("éšæœºç§å­", value=42)
        
        # æ‰§è¡Œé¢„å¤„ç†
        if st.button("æ‰§è¡Œé¢„å¤„ç†", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†..."):
                try:
                    # è¿™é‡Œåº”è¯¥è°ƒç”¨R APIè¿›è¡Œé¢„å¤„ç†
                    # æš‚æ—¶ä½¿ç”¨Pythonå®ç°ç®€å•é¢„å¤„ç†
                    
                    from sklearn.model_selection import train_test_split
                    from sklearn.preprocessing import StandardScaler, LabelEncoder
                    
                    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
                    X = df.drop(columns=[state.target_column])
                    y = df[state.target_column]
                    
                    # å¤„ç†ç¼ºå¤±å€¼
                    if missing_strategy == "åˆ é™¤ç¼ºå¤±è¡Œ":
                        X = X.dropna()
                        y = y[X.index]
                    elif missing_strategy == "å‡å€¼å¡«å……":
                        X = X.fillna(X.mean())
                    elif missing_strategy == "ä¸­ä½æ•°å¡«å……":
                        X = X.fillna(X.median())
                    elif missing_strategy == "ä¼—æ•°å¡«å……":
                        X = X.fillna(X.mode().iloc[0])
                    
                    # ç¼–ç åˆ†ç±»å˜é‡
                    if encode_categorical:
                        categorical_cols = X.select_dtypes(include=['object', 'category']).columns
                        for col in categorical_cols:
                            le = LabelEncoder()
                            X[col] = le.fit_transform(X[col])
                        
                        # ç¼–ç ç›®æ ‡å˜é‡ï¼ˆå¦‚æœæ˜¯åˆ†ç±»é—®é¢˜ï¼‰
                        if state.problem_type == "classification":
                            le_target = LabelEncoder()
                            y = le_target.fit_transform(y)
                    
                    # æ ‡å‡†åŒ–ç‰¹å¾
                    if scale_features:
                        numeric_cols = X.select_dtypes(include=[np.number]).columns
                        scaler = StandardScaler()
                        X[numeric_cols] = scaler.fit_transform(X[numeric_cols])
                    
                    # æ•°æ®åˆ†å‰²
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=test_size, random_state=random_seed
                    )
                    
                    # è¿›ä¸€æ­¥åˆ†å‰²éªŒè¯é›†
                    if validation_size > 0:
                        val_ratio = validation_size / (1 - test_size)
                        X_train, X_val, y_train, y_val = train_test_split(
                            X_train, y_train, test_size=val_ratio, random_state=random_seed
                        )
                    
                    # ä¿å­˜å¤„ç†åçš„æ•°æ®
                    state.processed_data = {
                        'X_train': X_train,
                        'X_test': X_test,
                        'y_train': y_train,
                        'y_test': y_test,
                        'feature_names': X.columns.tolist()
                    }
                    
                    if validation_size > 0:
                        state.processed_data.update({
                            'X_val': X_val,
                            'y_val': y_val
                        })
                    
                    st.success("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
                    
                    # æ˜¾ç¤ºå¤„ç†ç»“æœ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("è®­ç»ƒé›†", f"{len(X_train)} æ ·æœ¬")
                    with col2:
                        st.metric("æµ‹è¯•é›†", f"{len(X_test)} æ ·æœ¬")
                    with col3:
                        if validation_size > 0:
                            st.metric("éªŒè¯é›†", f"{len(X_val)} æ ·æœ¬")
                    
                    # ç‰¹å¾ä¿¡æ¯
                    with st.expander("ğŸ“‹ ç‰¹å¾ä¿¡æ¯", expanded=False):
                        st.write(f"**ç‰¹å¾æ•°é‡**: {len(X.columns)}")
                        st.write(f"**ç‰¹å¾åˆ—è¡¨**: {', '.join(X.columns.tolist()[:10])}")
                        if len(X.columns) > 10:
                            st.write(f"... è¿˜æœ‰ {len(X.columns) - 10} ä¸ªç‰¹å¾")
                    
                    # ä¸‹ä¸€æ­¥æŒ‰é’®
                    if st.button("ä¸‹ä¸€æ­¥: æ¨¡å‹è®­ç»ƒ", type="primary", use_container_width=True):
                        state.current_step = 4
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"é¢„å¤„ç†å¤±è´¥: {e}")
                    logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
    
    def page_model_training(self):
        """æ¨¡å‹è®­ç»ƒé¡µé¢"""
        st.markdown('<h2 class="section-title">ğŸ¤– æ¨¡å‹è®­ç»ƒ</h2>', 
                   unsafe_allow_html=True)
        
        if state.processed_data is None:
            st.warning("è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†")
            st.stop()
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("é€‰æ‹©ç®—æ³•")
        
        algorithm_options = {
            "é€»è¾‘å›å½’": "logistic",
            "éšæœºæ£®æ—": "random_forest",
            "æ¢¯åº¦æå‡æ ‘": "xgboost",
            "æ”¯æŒå‘é‡æœº": "svm",
            "ç¥ç»ç½‘ç»œ": "neural_network",
            "å†³ç­–æ ‘": "decision_tree",
            "Kæœ€è¿‘é‚»": "knn",
            "æœ´ç´ è´å¶æ–¯": "naive_bayes"
        }
        
        selected_algorithms = st.multiselect(
            "é€‰æ‹©è¦è®­ç»ƒçš„ç®—æ³•ï¼ˆå¯å¤šé€‰ï¼‰",
            list(algorithm_options.keys()),
            default=["é€»è¾‘å›å½’", "éšæœºæ£®æ—", "æ¢¯åº¦æå‡æ ‘"]
        )
        
        # è®­ç»ƒé…ç½®
        st.subheader("è®­ç»ƒé…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            cross_validation = st.checkbox("äº¤å‰éªŒè¯", value=True)
            if cross_validation:
                cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5)
            
            early_stopping = st.checkbox("æ—©åœæ³•", value=True)
            if early_stopping:
                patience = st.slider("è€å¿ƒå€¼", 5, 50, 10)
        
        with col2:
            hyperparameter_tuning = st.checkbox("è¶…å‚æ•°è°ƒä¼˜", value=True)
            if hyperparameter_tuning:
                tuning_method = st.selectbox(
                    "è°ƒä¼˜æ–¹æ³•",
                    ["ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–"]
                )
            
            ensemble_learning = st.checkbox("é›†æˆå­¦ä¹ ", value=False)
            if ensemble_learning:
                ensemble_method = st.selectbox(
                    "é›†æˆæ–¹æ³•",
                    ["æŠ•ç¥¨æ³•", "å †å æ³•", "Bagging", "Boosting"]
                )
        
        # é«˜çº§å‚æ•°é…ç½®
        with st.expander("ğŸ”§ é«˜çº§å‚æ•°é…ç½®"):
            tab1, tab2, tab3 = st.tabs(["éšæœºæ£®æ—", "XGBoost", "ç¥ç»ç½‘ç»œ"])
            
            with tab1:
                rf_n_estimators = st.slider("æ ‘çš„æ•°é‡", 10, 500, 100)
                rf_max_depth = st.slider("æœ€å¤§æ·±åº¦", 3, 20, 10)
                rf_min_samples_split = st.slider("æœ€å°åˆ†è£‚æ ·æœ¬æ•°", 2, 20, 2)
            
            with tab2:
                xgb_n_estimators = st.slider("æ ‘çš„æ•°é‡", 10, 500, 100)
                xgb_learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.3, 0.1, 0.01)
                xgb_max_depth = st.slider("æœ€å¤§æ·±åº¦", 3, 20, 6)
            
            with tab3:
                nn_hidden_layers = st.slider("éšè—å±‚å±‚æ•°", 1, 5, 2)
                nn_neurons_per_layer = st.slider("æ¯å±‚ç¥ç»å…ƒæ•°", 10, 200, 64)
                nn_activation = st.selectbox("æ¿€æ´»å‡½æ•°", ["relu", "sigmoid", "tanh"])
        
        # å¼€å§‹è®­ç»ƒ
        if st.button("å¼€å§‹è®­ç»ƒ", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
                try:
                    # æ„å»ºè®­ç»ƒé…ç½®
                    train_config = {
                        "algorithms": [algorithm_options[alg] for alg in selected_algorithms],
                        "problem_type": state.problem_type,
                        "cross_validation": cross_validation,
                        "cv_folds": cv_folds if cross_validation else None,
                        "hyperparameter_tuning": hyperparameter_tuning,
                        "tuning_method": tuning_method if hyperparameter_tuning else None,
                        "early_stopping": early_stopping,
                        "patience": patience if early_stopping else None,
                        "ensemble_learning": ensemble_learning,
                        "ensemble_method": ensemble_method if ensemble_learning else None,
                        "random_forest": {
                            "n_estimators": rf_n_estimators,
                            "max_depth": rf_max_depth,
                            "min_samples_split": rf_min_samples_split
                        },
                        "xgboost": {
                            "n_estimators": xgb_n_estimators,
                            "learning_rate": xgb_learning_rate,
                            "max_depth": xgb_max_depth
                        },
                        "neural_network": {
                            "hidden_layers": nn_hidden_layers,
                            "neurons_per_layer": nn_neurons_per_layer,
                            "activation": nn_activation
                        }
                    }
                    
                    # è°ƒç”¨R APIè¿›è¡Œè®­ç»ƒ
                    client = APIClient()
                    
                    # å‡†å¤‡è®­ç»ƒæ•°æ®
                    train_data = {
                        "X_train": state.processed_data["X_train"].to_dict(orient="list"),
                        "y_train": state.processed_data["y_train"].tolist(),
                        "X_test": state.processed_data["X_test"].to_dict(orient="list"),
                        "y_test": state.processed_data["y_test"].tolist(),
                        "feature_names": state.processed_data["feature_names"],
                        "config": train_config
                    }
                    
                    response = client.sync_request(
                        "POST",
                        "train_models",
                        json=train_data
                    )
                    
                    if response.get("success", False):
                        state.training_result = response
                        state.models_trained = True
                        
                        st.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
                        
                        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
                        self._show_training_results(response)
                        
                        # ä¸‹ä¸€æ­¥æŒ‰é’®
                        if st.button("ä¸‹ä¸€æ­¥: æ¨¡å‹è¯„ä¼°", type="primary", use_container_width=True):
                            state.current_step = 5
                            st.rerun()
                    else:
                        st.error(f"è®­ç»ƒå¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    st.error(f"è®­ç»ƒé”™è¯¯: {e}")
                    logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
    
    def _show_training_results(self, result):
        """æ˜¾ç¤ºè®­ç»ƒç»“æœ"""
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        st.subheader("æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        
        if "model_performance" in result:
            performance_data = []
            for model_name, perf in result["model_performance"].items():
                performance_data.append({
                    "æ¨¡å‹": model_name,
                    "å‡†ç¡®ç‡": perf.get("accuracy", 0),
                    "ç²¾ç¡®ç‡": perf.get("precision", 0),
                    "å¬å›ç‡": perf.get("recall", 0),
                    "F1åˆ†æ•°": perf.get("f1", 0),
                    "AUC": perf.get("auc", 0)
                })
            
            perf_df = pd.DataFrame(performance_data)
            st.dataframe(perf_df, use_container_width=True)
            
            # æ€§èƒ½å¯¹æ¯”å›¾
            fig = px.bar(
                perf_df.melt(id_vars=["æ¨¡å‹"], var_name="æŒ‡æ ‡", value_name="å€¼"),
                x="æ¨¡å‹", y="å€¼", color="æŒ‡æ ‡", barmode="group",
                title="æ¨¡å‹æ€§èƒ½å¯¹æ¯”"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # æœ€ä½³æ¨¡å‹
        if "best_model" in result:
            best_model = result["best_model"]
            st.subheader("æœ€ä½³æ¨¡å‹")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ¨¡å‹åç§°", best_model.get("name", "æœªçŸ¥"))
            with col2:
                st.metric("ç®—æ³•", best_model.get("algorithm", "æœªçŸ¥"))
            with col3:
                st.metric("å‡†ç¡®ç‡", f"{best_model.get('accuracy', 0):.4f}")
            with col4:
                st.metric("è®­ç»ƒæ—¶é—´", f"{best_model.get('training_time', 0):.2f}ç§’")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            state.selected_model = best_model
    
    def page_model_evaluation(self):
        """æ¨¡å‹è¯„ä¼°é¡µé¢"""
        st.markdown('<h2 class="section-title">ğŸ“ˆ æ¨¡å‹è¯„ä¼°</h2>', 
                   unsafe_allow_html=True)
        
        if not state.models_trained:
            st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            st.stop()
        
        # é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹
        model_options = list(state.training_result.get("model_performance", {}).keys())
        if not model_options:
            st.error("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            st.stop()
        
        selected_model = st.selectbox(
            "é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹",
            model_options,
            index=0
        )
        
        # è¯„ä¼°æŒ‡æ ‡
        st.subheader("è¯„ä¼°æŒ‡æ ‡")
        
        # è·å–æ¨¡å‹æ€§èƒ½
        model_perf = state.training_result["model_performance"].get(selected_model, {})
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å‡†ç¡®ç‡", f"{model_perf.get('accuracy', 0):.4f}")
        with col2:
            st.metric("ç²¾ç¡®ç‡", f"{model_perf.get('precision', 0):.4f}")
        with col3:
            st.metric("å¬å›ç‡", f"{model_perf.get('recall', 0):.4f}")
        with col4:
            st.metric("F1åˆ†æ•°", f"{model_perf.get('f1', 0):.4f}")
        
        # å¯è§†åŒ–
        st.subheader("æ¨¡å‹å¯è§†åŒ–")
        
        viz_type = st.selectbox(
            "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
            ["æ··æ·†çŸ©é˜µ", "ROCæ›²çº¿", "PRæ›²çº¿", "ç‰¹å¾é‡è¦æ€§", "å­¦ä¹ æ›²çº¿"]
        )
        
        if st.button("ç”Ÿæˆå¯è§†åŒ–", type="primary"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–..."):
                try:
                    # è°ƒç”¨R APIè·å–å¯è§†åŒ–
                    client = APIClient()
                    
                    viz_request = {
                        "model_name": selected_model,
                        "viz_type": viz_type,
                        "test_data": {
                            "X": state.processed_data["X_test"].to_dict(orient="list"),
                            "y": state.processed_data["y_test"].tolist()
                        }
                    }
                    
                    response = client.sync_request(
                        "POST",
                        "evaluate_model",
                        json=viz_request
                    )
                    
                    if response.get("success", False):
                        state.evaluation_result = response
                        
                        # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
                        self._show_evaluation_visualizations(response, viz_type)
                    else:
                        st.error(f"è·å–å¯è§†åŒ–å¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    st.error(f"è¯„ä¼°é”™è¯¯: {e}")
        
        # æ¨¡å‹è§£é‡Š
        st.subheader("æ¨¡å‹è§£é‡Š")
        
        if st.button("è§£é‡Šæ¨¡å‹", type="secondary"):
            with st.spinner("æ­£åœ¨è§£é‡Šæ¨¡å‹..."):
                try:
                    client = APIClient()
                    
                    explain_request = {
                        "model_name": selected_model,
                        "sample_data": state.processed_data["X_test"].iloc[0].to_dict()
                    }
                    
                    response = client.sync_request(
                        "POST",
                        "explain_model",
                        json=explain_request
                    )
                    
                    if response.get("success", False):
                        explanation = response.get("explanation", {})
                        
                        # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
                        if "feature_importance" in explanation:
                            st.markdown("## ç‰¹å¾é‡è¦æ€§")
                            importance_df = pd.DataFrame(
                                explanation["feature_importance"].items(),
                                columns=["ç‰¹å¾", "é‡è¦æ€§"]
                            ).sort_values("é‡è¦æ€§", ascending=False)
                            
                            st.dataframe(importance_df, use_container_width=True)
                            
                            # å¯è§†åŒ–
                            fig = px.bar(
                                importance_df.head(10),
                                x="é‡è¦æ€§", y="ç‰¹å¾", orientation='h',
                                title="Top 10 é‡è¦ç‰¹å¾"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # æ˜¾ç¤ºSHAPå€¼
                        if "shap_values" in explanation:
                            st.markdown("## SHAPå€¼åˆ†æ")
                            # è¿™é‡Œå¯ä»¥æ·»åŠ SHAPå¯è§†åŒ–
                    else:
                        st.warning("æ¨¡å‹è§£é‡ŠåŠŸèƒ½ä¸å¯ç”¨")
                        
                except Exception as e:
                    st.warning(f"æ¨¡å‹è§£é‡Šå¤±è´¥: {e}")
        
        # ä¸‹ä¸€æ­¥æŒ‰é’®
        if st.button("ä¸‹ä¸€æ­¥: æ¨¡å‹éƒ¨ç½²", type="primary", use_container_width=True):
            state.current_step = 6
            st.rerun()
    
    def _show_evaluation_visualizations(self, result, viz_type):
        """æ˜¾ç¤ºè¯„ä¼°å¯è§†åŒ–"""
        if viz_type == "æ··æ·†çŸ©é˜µ" and "confusion_matrix" in result:
            cm_data = result["confusion_matrix"]
            # è¿™é‡Œå¯ä»¥æ˜¾ç¤ºæ··æ·†çŸ©é˜µ
            st.write("æ··æ·†çŸ©é˜µ:")
            st.write(cm_data)
            
        elif viz_type == "ROCæ›²çº¿" and "roc_curve" in result:
            roc_data = result["roc_curve"]
            # è¿™é‡Œå¯ä»¥æ˜¾ç¤ºROCæ›²çº¿
            st.write("ROCæ›²çº¿æ•°æ®:")
            st.write(roc_data)
            
        elif viz_type == "ç‰¹å¾é‡è¦æ€§" and "feature_importance" in result:
            importance_data = result["feature_importance"]
            importance_df = pd.DataFrame(
                importance_data.items(),
                columns=["ç‰¹å¾", "é‡è¦æ€§"]
            ).sort_values("é‡è¦æ€§", ascending=False)
            
            st.dataframe(importance_df, use_container_width=True)
            
            fig = px.bar(
                importance_df.head(15),
                x="é‡è¦æ€§", y="ç‰¹å¾", orientation='h',
                title="ç‰¹å¾é‡è¦æ€§"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def page_model_deployment(self):
        """æ¨¡å‹éƒ¨ç½²é¡µé¢"""
        st.markdown('<h2 class="section-title">ğŸš€ æ¨¡å‹éƒ¨ç½²</h2>', 
                   unsafe_allow_html=True)
        
        if not state.models_trained:
            st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            st.stop()
        
        # éƒ¨ç½²é€‰é¡¹
        st.subheader("éƒ¨ç½²æ–¹å¼")
        
        deployment_type = st.radio(
            "é€‰æ‹©éƒ¨ç½²æ–¹å¼",
            ["REST API", "Dockerå®¹å™¨", "æ¨¡å‹æ–‡ä»¶", "äº‘æœåŠ¡"],
            horizontal=True
        )
        
        # æ¨¡å‹é€‰æ‹©
        model_options = list(state.training_result.get("model_performance", {}).keys())
        selected_model = st.selectbox(
            "é€‰æ‹©è¦éƒ¨ç½²çš„æ¨¡å‹",
            model_options
        )
        
        # éƒ¨ç½²é…ç½®
        if deployment_type == "REST API":
            self._show_api_deployment_config(selected_model)
        elif deployment_type == "Dockerå®¹å™¨":
            self._show_docker_deployment_config(selected_model)
        elif deployment_type == "æ¨¡å‹æ–‡ä»¶":
            self._show_model_file_config(selected_model)
        else:
            self._show_cloud_deployment_config(selected_model)
    
    def _show_api_deployment_config(self, model_name):
        """æ˜¾ç¤ºAPIéƒ¨ç½²é…ç½®"""
        st.subheader("REST APIéƒ¨ç½²é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            api_port = st.number_input("APIç«¯å£", 8000, 9000, 8080)
            api_host = st.text_input("ç»‘å®šåœ°å€", "127.0.0.1")
            enable_docs = st.checkbox("å¯ç”¨APIæ–‡æ¡£", value=True)
        
        with col2:
            rate_limit = st.number_input("è¯·æ±‚é™åˆ¶(æ¬¡/åˆ†é’Ÿ)", 10, 1000, 100)
            enable_auth = st.checkbox("å¯ç”¨è®¤è¯", value=False)
            if enable_auth:
                auth_method = st.selectbox("è®¤è¯æ–¹å¼", ["APIå¯†é’¥", "JWT", "OAuth2"])
        
        # éƒ¨ç½²æŒ‰é’®
        if st.button("éƒ¨ç½²ä¸ºREST API", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨éƒ¨ç½²APIæœåŠ¡..."):
                try:
                    client = APIClient()
                    
                    deploy_config = {
                        "model_name": model_name,
                        "deployment_type": "api",
                        "config": {
                            "port": api_port,
                            "host": api_host,
                            "enable_docs": enable_docs,
                            "rate_limit": rate_limit,
                            "enable_auth": enable_auth,
                            "auth_method": auth_method if enable_auth else None
                        }
                    }
                    
                    response = client.sync_request(
                        "POST",
                        "deploy_model",
                        json=deploy_config
                    )
                    
                    if response.get("success", False):
                        st.success("âœ… APIéƒ¨ç½²æˆåŠŸ")
                        
                        # æ˜¾ç¤ºAPIä¿¡æ¯
                        api_info = response.get("api_info", {})
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.info(f"**APIåœ°å€**: http://{api_host}:{api_port}")
                            st.info(f"**æ¨¡å‹ç«¯ç‚¹**: /predict")
                        with col2:
                            if enable_docs:
                                st.info(f"**æ–‡æ¡£åœ°å€**: http://{api_host}:{api_port}/__swagger__/")
                        
                        # æµ‹è¯•API
                        if st.button("æµ‹è¯•API", type="secondary"):
                            self._test_api_endpoint(api_host, api_port, model_name)
                    else:
                        st.error(f"éƒ¨ç½²å¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    st.error(f"éƒ¨ç½²é”™è¯¯: {e}")
    
    def _show_docker_deployment_config(self, model_name):
        """æ˜¾ç¤ºDockeréƒ¨ç½²é…ç½®"""
        st.subheader("Dockerå®¹å™¨éƒ¨ç½²é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            docker_image = st.text_input("é•œåƒåç§°", f"mlweb-{model_name}")
            docker_tag = st.text_input("é•œåƒæ ‡ç­¾", "latest")
            expose_port = st.number_input("æš´éœ²ç«¯å£", 8000, 9000, 8080)
        
        with col2:
            enable_gpu = st.checkbox("å¯ç”¨GPUæ”¯æŒ", value=False)
            resource_limit = st.checkbox("èµ„æºé™åˆ¶", value=False)
            if resource_limit:
                cpu_limit = st.text_input("CPUé™åˆ¶", "2")
                memory_limit = st.text_input("å†…å­˜é™åˆ¶", "4g")
        
        # ç”ŸæˆDockerfile
        if st.button("ç”ŸæˆDockerfile", type="secondary"):
            dockerfile = f"""FROM rocker/r-ver:4.3.0

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \\
    python3 \\
    python3-pip \\
    libcurl4-openssl-dev \\
    libssl-dev \\
    libxml2-dev \\
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# å¤åˆ¶æ¨¡å‹æ–‡ä»¶
COPY models/{model_name}.rds ./model.rds
COPY r_scripts/ ./r_scripts/

# å®‰è£…Rä¾èµ–
RUN Rscript -e "install.packages(c('plumber', 'caret', 'jsonlite'), repos='https://cloud.r-project.org')"

# åˆ›å»ºAPIæ–‡ä»¶
COPY plumber_api.R .

# æš´éœ²ç«¯å£
EXPOSE {expose_port}

# å¯åŠ¨å‘½ä»¤
CMD ["Rscript", "-e", "library(plumber); pr <- plumb('plumber_api.R'); pr$run(host='127.0.0.1', port={expose_port})"]"""
            
            st.code(dockerfile, language="dockerfile")
            
            # ä¸‹è½½Dockerfile
            b64 = base64.b64encode(dockerfile.encode()).decode()
            href = f'<a href="data:text/plain;base64,{b64}" download="Dockerfile">ä¸‹è½½Dockerfile</a>'
            st.markdown(href, unsafe_allow_html=True)
        
        # æ„å»ºé•œåƒ
        if st.button("æ„å»ºDockeré•œåƒ", type="primary", use_container_width=True):
            st.info("è¯·åœ¨ç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤:")
            st.code(f"docker build -t {docker_image}:{docker_tag} .")
            st.code(f"docker run -p {expose_port}:{expose_port} {docker_image}:{docker_tag}")
    
    def _show_model_file_config(self, model_name):
        """æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶é…ç½®"""
        st.subheader("æ¨¡å‹æ–‡ä»¶å¯¼å‡º")
        
        export_format = st.radio(
            "å¯¼å‡ºæ ¼å¼",
            [".rds (Ræ ¼å¼)", ".pmml (é€šç”¨æ ¼å¼)", ".onnx (æ·±åº¦å­¦ä¹ )", ".pkl (Pythonæ ¼å¼)"],
            horizontal=True
        )
        
        include_preprocessor = st.checkbox("åŒ…å«é¢„å¤„ç†ç®¡é“", value=True)
        include_documentation = st.checkbox("åŒ…å«ä½¿ç”¨æ–‡æ¡£", value=True)
        
        if st.button("å¯¼å‡ºæ¨¡å‹æ–‡ä»¶", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å¯¼å‡ºæ¨¡å‹..."):
                try:
                    client = APIClient()
                    
                    export_config = {
                        "model_name": model_name,
                        "export_format": export_format.split(" ")[0].lstrip("."),
                        "include_preprocessor": include_preprocessor,
                        "include_documentation": include_documentation
                    }
                    
                    response = client.sync_request(
                        "POST",
                        "export_model",
                        json=export_config
                    )
                    
                    if response.get("success", False):
                        st.success("âœ… æ¨¡å‹å¯¼å‡ºæˆåŠŸ")
                        
                        # æä¾›ä¸‹è½½
                        if "file_content" in response:
                            file_format = export_format.split(" ")[0].lstrip(".")
                            file_name = f"{model_name}.{file_format}"
                            
                            if file_format == "rds":
                                mime_type = "application/octet-stream"
                            elif file_format == "pmml":
                                mime_type = "application/xml"
                            elif file_format == "onnx":
                                mime_type = "application/octet-stream"
                            else:
                                mime_type = "application/octet-stream"
                            
                            b64 = base64.b64encode(response["file_content"].encode()).decode()
                            href = f'<a href="data:{mime_type};base64,{b64}" download="{file_name}">ä¸‹è½½æ¨¡å‹æ–‡ä»¶</a>'
                            st.markdown(href, unsafe_allow_html=True)
                    else:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    st.error(f"å¯¼å‡ºé”™è¯¯: {e}")
    
    def _show_cloud_deployment_config(self, model_name):
        """æ˜¾ç¤ºäº‘æœåŠ¡éƒ¨ç½²é…ç½®"""
        st.subheader("äº‘æœåŠ¡éƒ¨ç½²")
        
        cloud_provider = st.selectbox(
            "äº‘æœåŠ¡å•†",
            ["AWS SageMaker", "Google AI Platform", "Azure ML", "é˜¿é‡Œäº‘PAI", "åä¸ºäº‘ModelArts"]
        )
        
        if cloud_provider == "AWS SageMaker":
            st.text_input("SageMakerç«¯ç‚¹åç§°", f"mlweb-{model_name}")
            st.text_input("IAMè§’è‰²ARN", "arn:aws:iam::123456789012:role/SageMakerRole")
            st.text_input("S3å­˜å‚¨æ¡¶", "mlweb-models")
            
        elif cloud_provider == "Google AI Platform":
            st.text_input("é¡¹ç›®ID", "your-project-id")
            st.text_input("æ¨¡å‹åç§°", f"mlweb_{model_name}")
            st.selectbox("æœºå™¨ç±»å‹", ["n1-standard-4", "n1-highmem-8", "n1-highcpu-16"])
            
        elif cloud_provider == "Azure ML":
            st.text_input("å·¥ä½œåŒºåç§°", "mlweb-workspace")
            st.text_input("æ¨¡å‹åç§°", f"mlweb-{model_name}")
            st.selectbox("è®¡ç®—ç›®æ ‡", ["local", "amlcompute", "aks"])
        
        st.warning("äº‘æœåŠ¡éƒ¨ç½²åŠŸèƒ½éœ€è¦ç›¸åº”çš„äº‘å¹³å°è´¦æˆ·å’Œé…ç½®")
        
        if st.button("éƒ¨ç½²åˆ°äº‘å¹³å°", type="primary", disabled=True):
            st.info("æ­¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­")
    
    def _test_api_endpoint(self, host, port, model_name):
        """æµ‹è¯•APIç«¯ç‚¹"""
        test_url = f"http://{host}:{port}/health"
        
        try:
            response = requests.get(test_url, timeout=5)
            if response.status_code == 200:
                st.success("âœ… APIå¥åº·æ£€æŸ¥é€šè¿‡")
                
                # æµ‹è¯•é¢„æµ‹ç«¯ç‚¹
                if state.processed_data is not None:
                    sample_data = state.processed_data["X_test"].iloc[0].to_dict()
                    
                    predict_url = f"http://{host}:{port}/predict"
                    predict_response = requests.post(
                        predict_url,
                        json=sample_data,
                        timeout=10
                    )
                    
                    if predict_response.status_code == 200:
                        st.success("âœ… é¢„æµ‹ç«¯ç‚¹æµ‹è¯•é€šè¿‡")
                        result = predict_response.json()
                        st.write("é¢„æµ‹ç»“æœ:", result)
                    else:
                        st.error(f"âŒ é¢„æµ‹ç«¯ç‚¹æµ‹è¯•å¤±è´¥: {predict_response.status_code}")
            else:
                st.error(f"âŒ APIå¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            st.error(f"âŒ APIæµ‹è¯•å¤±è´¥: {e}")
    
    def page_realtime_prediction(self):
        """å®æ—¶é¢„æµ‹é¡µé¢"""
        st.markdown('<h2 class="section-title">âš¡ å®æ—¶é¢„æµ‹</h2>', 
                   unsafe_allow_html=True)
        
        if not state.models_trained:
            st.warning("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            st.stop()
        
        # é¢„æµ‹æ–¹å¼é€‰æ‹©
        predict_mode = st.radio(
            "é¢„æµ‹æ–¹å¼",
            ["å•æ ·æœ¬é¢„æµ‹", "æ‰¹é‡é¢„æµ‹", "æ–‡ä»¶é¢„æµ‹", "APIè°ƒç”¨"],
            horizontal=True
        )
        
        if predict_mode == "å•æ ·æœ¬é¢„æµ‹":
            self._show_single_prediction()
        elif predict_mode == "æ‰¹é‡é¢„æµ‹":
            self._show_batch_prediction()
        elif predict_mode == "æ–‡ä»¶é¢„æµ‹":
            self._show_file_prediction()
        else:
            self._show_api_prediction()
    
    def _show_single_prediction(self):
        """æ˜¾ç¤ºå•æ ·æœ¬é¢„æµ‹"""
        st.subheader("å•æ ·æœ¬é¢„æµ‹")
        
        if state.processed_data is None:
            st.warning("è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†")
            st.stop()
        
        # è·å–ç‰¹å¾åˆ—è¡¨
        feature_names = state.processed_data["feature_names"]
        
        # åŠ¨æ€ç”Ÿæˆè¾“å…¥è¡¨å•
        st.markdown("## è¾“å…¥ç‰¹å¾å€¼")
        
        inputs = {}
        cols = st.columns(3)
        
        for i, feature in enumerate(feature_names):
            with cols[i % 3]:
                # è·å–ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ç”¨äºè¾“å…¥èŒƒå›´
                if state.raw_data is not None and feature in state.raw_data.columns:
                    col_data = state.raw_data[feature]
                    if pd.api.types.is_numeric_dtype(col_data):
                        min_val = float(col_data.min())
                        max_val = float(col_data.max())
                        mean_val = float(col_data.mean())
                        
                        inputs[feature] = st.number_input(
                            feature,
                            min_value=min_val,
                            max_value=max_val,
                            value=mean_val,
                            help=f"èŒƒå›´: [{min_val:.2f}, {max_val:.2f}]"
                        )
                    else:
                        unique_vals = col_data.unique()[:10]  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªå€¼
                        inputs[feature] = st.selectbox(feature, unique_vals)
                else:
                    inputs[feature] = st.number_input(feature, value=0.0)
        
        # é€‰æ‹©æ¨¡å‹
        model_options = list(state.training_result.get("model_performance", {}).keys())
        selected_model = st.selectbox("é€‰æ‹©é¢„æµ‹æ¨¡å‹", model_options)
        
        # é¢„æµ‹æŒ‰é’®
        if st.button("è¿›è¡Œé¢„æµ‹", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨é¢„æµ‹..."):
                try:
                    client = APIClient()
                    
                    prediction_request = {
                        "model_name": selected_model,
                        "input_data": inputs
                    }
                    
                    response = client.sync_request(
                        "POST",
                        "predict",
                        json=prediction_request
                    )
                    
                    if response.get("success", False):
                        result = response.get("result", {})
                        
                        st.success("âœ… é¢„æµ‹å®Œæˆ")
                        
                        # æ˜¾ç¤ºç»“æœ
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("é¢„æµ‹å€¼", f"{result.get('prediction', 'N/A')}")
                        with col2:
                            if "probability" in result:
                                st.metric("ç½®ä¿¡åº¦", f"{result['probability']:.2%}")
                        with col3:
                            st.metric("å“åº”æ—¶é—´", f"{result.get('response_time', 0):.3f}ç§’")
                        
                        # è¯¦ç»†ä¿¡æ¯
                        with st.expander("ğŸ“‹ é¢„æµ‹è¯¦æƒ…", expanded=False):
                            st.json(result)
                        
                        # é¢„æµ‹è§£é‡Š
                        if st.button("è§£é‡Šé¢„æµ‹ç»“æœ", type="secondary"):
                            self._explain_prediction(selected_model, inputs)
                    else:
                        st.error(f"é¢„æµ‹å¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    st.error(f"é¢„æµ‹é”™è¯¯: {e}")
    
    def _show_batch_prediction(self):
        """æ˜¾ç¤ºæ‰¹é‡é¢„æµ‹"""
        st.subheader("æ‰¹é‡é¢„æµ‹")
        
        # è¾“å…¥æ–¹å¼é€‰æ‹©
        input_method = st.radio(
            "è¾“å…¥æ–¹å¼",
            ["æ‰‹åŠ¨è¾“å…¥", "ä¸Šä¼ æ–‡ä»¶", "ä»æ•°æ®åº“"],
            horizontal=True
        )
        
        if input_method == "æ‰‹åŠ¨è¾“å…¥":
            # JSONè¾“å…¥
            default_json = '[{"feature1": 5.1, "feature2": 3.5}, {"feature1": 6.2, "feature2": 3.4}]'
            input_json = st.text_area(
                "è¾“å…¥JSONæ ¼å¼æ•°æ®",
                value=default_json,
                height=200
            )
            
            try:
                data = json.loads(input_json)
                st.success(f"âœ… è§£ææˆåŠŸï¼Œå…± {len(data)} æ¡è®°å½•")
                
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSONæ ¼å¼é”™è¯¯: {e}")
                data = None
                
        elif input_method == "ä¸Šä¼ æ–‡ä»¶":
            uploaded_file = st.file_uploader(
                "é€‰æ‹©æ•°æ®æ–‡ä»¶",
                type=["csv", "json", "xlsx"],
                help="æ”¯æŒCSVã€JSONã€Excelæ ¼å¼"
            )
            
            if uploaded_file is not None:
                try:
                    if uploaded_file.name.endswith('.csv'):
                        data = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith('.json'):
                        data = pd.read_json(uploaded_file)
                    elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                        data = pd.read_excel(uploaded_file)
                    
                    st.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ: {len(data)} æ¡è®°å½•")
                    st.dataframe(data.head(), use_container_width=True)
                    
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                    data = None
            else:
                data = None
                
        else:  # ä»æ•°æ®åº“
            st.info("æ•°æ®åº“è¾“å…¥åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­")
            data = None
        
        # é€‰æ‹©æ¨¡å‹
        if data is not None:
            model_options = list(state.training_result.get("model_performance", {}).keys())
            selected_model = st.selectbox("é€‰æ‹©é¢„æµ‹æ¨¡å‹", model_options)
            
            if st.button("æ‰¹é‡é¢„æµ‹", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨è¿›è¡Œæ‰¹é‡é¢„æµ‹..."):
                    try:
                        client = APIClient()
                        
                        # è½¬æ¢æ•°æ®æ ¼å¼
                        if isinstance(data, pd.DataFrame):
                            batch_data = data.to_dict(orient="records")
                        else:
                            batch_data = data
                        
                        batch_request = {
                            "model_name": selected_model,
                            "batch_data": batch_data
                        }
                        
                        response = client.sync_request(
                            "POST",
                            "batch_predict",
                            json=batch_request
                        )
                        
                        if response.get("success", False):
                            result = response.get("result", {})
                            
                            st.success(f"âœ… æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œå…± {result.get('count', 0)} æ¡è®°å½•")
                            
                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("æ€»è€—æ—¶", f"{result.get('total_time', 0):.3f}ç§’")
                            with col2:
                                st.metric("å¹³å‡è€—æ—¶", 
                                         f"{result.get('avg_time_per_prediction', 0):.3f}ç§’/æ ·æœ¬")
                            with col3:
                                predictions = result.get('predictions', [])
                                if predictions:
                                    st.metric("å¹³å‡é¢„æµ‹å€¼", f"{np.mean(predictions):.4f}")
                            
                            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                            predictions_df = pd.DataFrame({
                                "åºå·": range(1, len(predictions) + 1),
                                "é¢„æµ‹å€¼": predictions
                            })
                            
                            if "probabilities" in result:
                                predictions_df["ç½®ä¿¡åº¦"] = result["probabilities"]
                            
                            st.dataframe(predictions_df, use_container_width=True)
                            
                            # é¢„æµ‹åˆ†å¸ƒ
                            if predictions:
                                fig = px.histogram(predictions_df, x="é¢„æµ‹å€¼", 
                                                 nbins=20, title="é¢„æµ‹å€¼åˆ†å¸ƒ")
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # ä¸‹è½½ç»“æœ
                            csv = predictions_df.to_csv(index=False)
                            st.download_button(
                                label="ä¸‹è½½é¢„æµ‹ç»“æœ",
                                data=csv,
                                file_name="batch_predictions.csv",
                                mime="text/csv"
                            )
                        else:
                            st.error(f"æ‰¹é‡é¢„æµ‹å¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            
                    except Exception as e:
                        st.error(f"æ‰¹é‡é¢„æµ‹é”™è¯¯: {e}")
    
    def _show_file_prediction(self):
        """æ˜¾ç¤ºæ–‡ä»¶é¢„æµ‹"""
        st.subheader("æ–‡ä»¶é¢„æµ‹")
        
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "json"],
            help="æ–‡ä»¶åº”åŒ…å«ä¸è®­ç»ƒæ•°æ®ç›¸åŒçš„ç‰¹å¾åˆ—"
        )
        
        if uploaded_file is not None:
            # é¢„è§ˆæ–‡ä»¶
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith('.json'):
                    df = pd.read_json(uploaded_file)
                elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                    df = pd.read_excel(uploaded_file)
                
                st.success(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
                
                with st.expander("ğŸ“‹ æ•°æ®é¢„è§ˆ", expanded=True):
                    st.dataframe(df.head(), use_container_width=True)
                
                # é€‰æ‹©æ¨¡å‹
                model_options = list(state.training_result.get("model_performance", {}).keys())
                selected_model = st.selectbox("é€‰æ‹©é¢„æµ‹æ¨¡å‹", model_options)
                
                if st.button("æ‰§è¡Œæ–‡ä»¶é¢„æµ‹", type="primary", use_container_width=True):
                    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
                        df.to_csv(tmp_file.name, index=False)
                        tmp_path = tmp_file.name
                    
                    with st.spinner("æ­£åœ¨è¿›è¡Œæ–‡ä»¶é¢„æµ‹..."):
                        try:
                            client = APIClient()
                            
                            file_request = {
                                "model_name": selected_model,
                                "file_path": tmp_path
                            }
                            
                            response = client.sync_request(
                                "POST",
                                "file_predict",
                                json=file_request
                            )
                            
                            if response.get("success", False):
                                result = response.get("result", {})
                                
                                st.success(f"âœ… æ–‡ä»¶é¢„æµ‹å®Œæˆï¼Œå…± {result.get('count', 0)} æ¡è®°å½•")
                                
                                # åˆå¹¶é¢„æµ‹ç»“æœ
                                predictions = result.get('predictions', [])
                                result_df = df.copy()
                                result_df['é¢„æµ‹å€¼'] = predictions
                                
                                if "probabilities" in result:
                                    result_df['ç½®ä¿¡åº¦'] = result['probabilities']
                                
                                st.dataframe(result_df, use_container_width=True)
                                
                                # ä¸‹è½½å®Œæ•´ç»“æœ
                                csv = result_df.to_csv(index=False)
                                st.download_button(
                                    label="ä¸‹è½½å®Œæ•´ç»“æœ",
                                    data=csv,
                                    file_name="file_predictions.csv",
                                    mime="text/csv"
                                )
                            else:
                                st.error(f"æ–‡ä»¶é¢„æµ‹å¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                                
                        except Exception as e:
                            st.error(f"æ–‡ä»¶é¢„æµ‹é”™è¯¯: {e}")
                        finally:
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            if os.path.exists(tmp_path):
                                os.unlink(tmp_path)
                                
            except Exception as e:
                st.error(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    def _show_api_prediction(self):
        """æ˜¾ç¤ºAPIè°ƒç”¨é¢„æµ‹"""
        st.subheader("APIè°ƒç”¨")
        
        st.info("""
        ## ä½¿ç”¨APIè¿›è¡Œé¢„æµ‹
        
        æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç«¯ç‚¹é€šè¿‡HTTPè¯·æ±‚è¿›è¡Œé¢„æµ‹:
        
        **å¥åº·æ£€æŸ¥**
        ```bash
        GET /health
        ```
        
        **å•æ ·æœ¬é¢„æµ‹**
        ```bash
        POST /predict
        Content-Type: application/json
        
        {
          "model_name": "model_name",
          "input_data": {
            "feature1": 5.1,
            "feature2": 3.5,
            ...
          }
        }
        ```
        
        **æ‰¹é‡é¢„æµ‹**
        ```bash
        POST /batch_predict
        Content-Type: application/json
        
        {
          "model_name": "model_name",
          "batch_data": [
            {"feature1": 5.1, "feature2": 3.5},
            {"feature1": 6.2, "feature2": 3.4},
            ...
          ]
        }
        ```
        
        **æ–‡ä»¶é¢„æµ‹**
        ```bash
        POST /file_predict
        Content-Type: application/json
        
        {
          "model_name": "model_name",
          "file_path": "/path/to/data.csv"
        }
        ```
        """)
        
        # APIæµ‹è¯•
        st.subheader("APIæµ‹è¯•")
        
        api_url = st.text_input("APIåœ°å€", config.API_BASE_URL)
        endpoint = st.selectbox("æµ‹è¯•ç«¯ç‚¹", ["/health", "/predict", "/models"])
        
        if endpoint == "/predict" and state.processed_data is not None:
            sample_data = state.processed_data["X_test"].iloc[0].to_dict()
            st.code(f"""
            curl -X POST {api_url}/predict \\
                 -H "Content-Type: application/json" \\
                 -d '{json.dumps({"input_data": sample_data}, indent=2)}'
            """)
        else:
            st.code(f"curl {api_url}{endpoint}")
    
    def _explain_prediction(self, model_name, input_data):
        """è§£é‡Šå•ä¸ªé¢„æµ‹"""
        try:
            client = APIClient()
            
            explain_request = {
                "model_name": model_name,
                "input_data": input_data
            }
            
            response = client.sync_request(
                "POST",
                "explain_prediction",
                json=explain_request
            )
            
            if response.get("success", False):
                explanation = response.get("explanation", {})
                
                st.subheader("é¢„æµ‹è§£é‡Š")
                
                # ç‰¹å¾è´¡çŒ®
                if "feature_contributions" in explanation:
                    contrib_data = explanation["feature_contributions"]
                    contrib_df = pd.DataFrame(
                        contrib_data.items(),
                        columns=["ç‰¹å¾", "è´¡çŒ®åº¦"]
                    ).sort_values("è´¡çŒ®åº¦", ascending=False)
                    
                    st.dataframe(contrib_df, use_container_width=True)
                    
                    # å¯è§†åŒ–
                    fig = px.bar(
                        contrib_df,
                        x="è´¡çŒ®åº¦", y="ç‰¹å¾", orientation='h',
                        title="ç‰¹å¾è´¡çŒ®åº¦"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # å†³ç­–è¾¹ç•Œåˆ†æ
                if "decision_boundary" in explanation:
                    st.markdown("## å†³ç­–è¾¹ç•Œåˆ†æ")
                    # è¿™é‡Œå¯ä»¥æ˜¾ç¤ºå†³ç­–è¾¹ç•Œå¯è§†åŒ–
                    
            else:
                st.warning("é¢„æµ‹è§£é‡ŠåŠŸèƒ½ä¸å¯ç”¨")
                
        except Exception as e:
            st.warning(f"é¢„æµ‹è§£é‡Šå¤±è´¥: {e}")

# ä¸»åº”ç”¨
def main():
    """ä¸»åº”ç”¨å…¥å£"""
    
    # åˆå§‹åŒ–é¡µé¢æ§åˆ¶å™¨
    controller = PageController()
    
    # æ£€æŸ¥APIè¿æ¥
    if state.last_api_check is None or time.time() - state.last_api_check > 30:
        client = APIClient()
        status = client.check_health()
        state.api_status = status
        state.api_available = (status.get("status") == "healthy")
        state.last_api_check = time.time()
    
    # æ¸²æŸ“é¡µé¢
    controller.render()
    
    # æ€§èƒ½ç›‘æ§
    if st.sidebar.checkbox("æ˜¾ç¤ºæ€§èƒ½ç›‘æ§", value=False):
        with st.sidebar.expander("ğŸ“Š æ€§èƒ½ç›‘æ§", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                st.metric("å†…å­˜ä½¿ç”¨", f"{psutil.Process().memory_info().rss / 1024 / 1024:.1f} MB")
            with col2:
                st.metric("CPUä½¿ç”¨", f"{psutil.cpu_percent()}%")
            
            # APIç»Ÿè®¡
            if state.api_available:
                client = APIClient()
                stats = client.get_stats()
                st.write("**APIç»Ÿè®¡**:")
                st.write(f"- æ€»è¯·æ±‚: {stats['total_requests']}")
                st.write(f"- æˆåŠŸç‡: {stats['success_rate']:.1%}")

if __name__ == "__main__":
    # å¯¼å…¥psutilç”¨äºç›‘æ§
    try:
        import psutil
    except ImportError:
        st.warning("å®‰è£…psutilä»¥å¯ç”¨æ€§èƒ½ç›‘æ§: pip install psutil")
        psutil = None
    
    main()